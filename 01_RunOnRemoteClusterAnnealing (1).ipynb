{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Chem Implementation with Cost Annealing, and without teacher forcing\n",
    "_**Cost Leverages the SMILES **_\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.runconfig import RunConfiguration, DEFAULT_GPU_IMAGE\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cluster_name = 'mmdsvm04d'\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('found existing:', compute_target.name)\n",
    "except ComputeTargetException:\n",
    "    print('creating new.')\n",
    "    compute_config = AmlCompute.provisioning_configuration(\n",
    "        vm_size='STANDARD_NC12',\n",
    "        min_nodes=0,\n",
    "        max_nodes=1)\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "    compute_target.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "myenv = Environment('deepchem_backend2')\n",
    "\n",
    "#already created\n",
    "conda_dep = CondaDependencies().create(python_version='3.7.10', conda_packages=['tensorflow-gpu==2.4.1', 'rdkit', 'openmm', 'pdbfixer'])\n",
    "conda_dep.add_channel(\"conda-forge\")\n",
    "conda_dep.add_channel(\"omnia\")\n",
    "conda_dep.add_pip_package(\"azureml-sdk\")\n",
    "conda_dep.add_pip_package(\"deepchem\")\n",
    "#1.19.4\n",
    "conda_dep.add_pip_package(\"numpy==1.19.4\")\n",
    "#IPython\n",
    "conda_dep.add_pip_package(\"IPython\")\n",
    "conda_dep.save(path=\"./train/condadep.yml\")\n",
    "myenv.python.conda_dependencies=conda_dep\n",
    "#myenv.docker.enabled = True\n",
    "myenv.docker.base_image = DEFAULT_GPU_IMAGE\n",
    "myenv.register(workspace=ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "current_dir = cwd\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "script_folder = os.path.join(os.getcwd(), \"train\")\n",
    "print(script_folder)\n",
    "os.makedirs(script_folder, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $script_folder/train.py\n",
    "\n",
    "\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import requests\n",
    "import subprocess\n",
    "import shutil\n",
    "import IPython\n",
    "from logging import getLogger, StreamHandler, INFO\n",
    "from deepchem.models.optimizers import Adam, ExponentialDecay\n",
    "from deepchem.models.seqtoseq import AspuruGuzikAutoEncoder\n",
    "import rdkit\n",
    "import numpy as np\n",
    "import deepchem\n",
    "import rdkit\n",
    "import tensorflow as tf\n",
    "from azureml.core import Run\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "import random\n",
    "\n",
    "# DEFINE THE MODEL\n",
    "def get_model(train_smiles, tokens, max_length, learning_rate):\n",
    "    run = Run.get_context()\n",
    "    batch_size = 100\n",
    "    \n",
    "    #A learning rate that decreases exponentially with the number of training steps.\n",
    "    #(initial_rate: float, decay_rate: float, decay_steps: int, staircase: bool = True)\n",
    "    run.log('learningRate', learning_rate)\n",
    "    learning_rate = ExponentialDecay(learning_rate, 0.95, len(train_smiles)/batch_size)\n",
    "    \n",
    "    model = AspuruGuzikAutoEncoder(tokens, max_length, model_dir='vae', batch_size=batch_size, learning_rate=learning_rate)\n",
    "    return model\n",
    "\n",
    "# GENERATE MOLECULES AND TEST IF THEY ARE VALID\n",
    "def generate_molecules(model, zinc_data, n_molecules=5000):\n",
    "    run = Run.get_context()\n",
    "    run.log('n_moleculesd', n_molecules)\n",
    "    \n",
    "    predictions = model.predict_from_embeddings(np.random.normal(size=(n_molecules,196))) \n",
    "    valid = []\n",
    "\n",
    "    #using chem from rdkit to ensure generated molecules are valid\n",
    "    count = 0\n",
    "    for p in predictions:\n",
    "        count += 1\n",
    "        smiles = ''.join(p)\n",
    "        if count < 25:\n",
    "            print(smiles)\n",
    "        if rdkit.Chem.MolFromSmiles(smiles) is not None:\n",
    "            valid.append(smiles) \n",
    "\n",
    "    print(len(valid) / n_molecules)\n",
    "    \n",
    "    run.log('valid', (len(valid) / n_molecules))\n",
    "    i = 0\n",
    "\n",
    "#     print('**************************')\n",
    "#     for s in valid:\n",
    "#         i = i + 1\n",
    "#         print(s)\n",
    "#         output_dir = './outputs/'\n",
    "#         os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "#         mol = rdkit.Chem.MolFromSmiles(s)\n",
    "#         filename = os.path.join(output_dir, 'image' + str(i) + '_' + s + '.png')\n",
    "#         print(filename)\n",
    "#         rdkit.Chem.Draw.MolToFile(mol, filename)\n",
    "  \n",
    "#     print('***************************')\n",
    "    \n",
    "    \n",
    "#     print('looking for winners')\n",
    "#     valid_in_zinc = []\n",
    "#     for x in valid:\n",
    "#         if x in zinc_data:\n",
    "#             print('Found a winner')\n",
    "#             valid_in_zinc.append(x)\n",
    "            \n",
    "    \n",
    "#     run.log('valid_in_zinc', len(valid_in_zinc))\n",
    "#     print(len(valid_in_zinc))\n",
    "    \n",
    "#     if len(valid) > 0:\n",
    "#         print(len(valid_in_zinc)/len(valid))\n",
    "#         run.log('valid_in_zinc_out_of_valid', len(valid_in_zinc)/len(valid))\n",
    "#     else:\n",
    "#         run.log('valid_in_zinc_out_of_valid', 0)\n",
    "\n",
    "    \n",
    "#     print(len(valid_in_zinc)/n_molecules)\n",
    "#     run.log('valid_in_zinc_out_of_all_generated', len(valid_in_zinc)/n_molecules)\n",
    "    \n",
    "\n",
    "\n",
    "def get_mol(smiles):\n",
    "    mol = rdkit.Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    return rdkit.Chem.Kekulize(mol)\n",
    "   \n",
    "\n",
    "\n",
    "def generate_sequences(epochs, train_smiles): \n",
    "    run = Run.get_context()\n",
    "    run.log('epochs', epochs)\n",
    "    for i in range(epochs):\n",
    "        print('epoch:', i+1)\n",
    "        for s in train_smiles: \n",
    "            yield (s, s)\n",
    "            \n",
    "\n",
    "#deepchem has its own fit model variation\n",
    "def train(model, train_smiles, epochs=1):\n",
    "    model.fit_sequences(generate_sequences(epochs, train_smiles))\n",
    "\n",
    "    \n",
    "def modeltrain(epoch_count, learning_rate, sampling_size): \n",
    "\n",
    "    os.makedirs('data', exist_ok = True)\n",
    "    run = Run.get_context()\n",
    "    tasks, datasets, _ = deepchem.molnet.load_zinc15(\n",
    "    featurizer='raw',\n",
    "    splitter=None,\n",
    "    transformers=[],\n",
    "    data_dir='data', \n",
    "    save_dir='data')\n",
    "    print(tasks)\n",
    "\n",
    "\n",
    "    data = datasets[0]\n",
    "    train_smiles = []\n",
    "    for X, _, _, _ in data.itersamples():\n",
    "        train_smiles.append(rdkit.Chem.MolToSmiles(X))\n",
    "    print(len(train_smiles))\n",
    "    run.log('datasetsize', len(train_smiles))\n",
    "    for smile in train_smiles[0:5]:\n",
    "        print(smile)\n",
    "\n",
    "    # DEFINE THE SMILES TOKENS AND MAX_LENGTHS\n",
    "    tokens = set()\n",
    "    for s in train_smiles:\n",
    "        tokens = tokens.union(set(s))\n",
    "    tokens = sorted(list(tokens))\n",
    "    max_length = max(len(s) for s in train_smiles)\n",
    "\n",
    "    try:\n",
    "        seed = 123\n",
    "        tf.random.set_seed(seed)\n",
    "        device_name = tf.test.gpu_device_name()\n",
    "        print('***************')\n",
    "        print(device_name)\n",
    "        print('***************')\n",
    "        run.log('device_name', device_name)\n",
    "\n",
    "        with tf.device(device_name):\n",
    "            model = get_model(train_smiles, tokens, max_length, learning_rate)\n",
    "            train(model, train_smiles, epoch_count)\n",
    "            generate_molecules(model, train_smiles, sampling_size)\n",
    "\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    seed = 123\n",
    "    random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    #os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "    print('in main')\n",
    "    epoch_count = 2\n",
    "    learning_rate = .0001\n",
    "    sampling_size = 100000\n",
    "    modeltrain(epoch_count, learning_rate, sampling_size)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment, ScriptRunConfig\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "experiment = Experiment(workspace = ws, name = \"vae-no-teacher-forcing-run-410i\")\n",
    "script_config = ScriptRunConfig(source_directory = script_folder, script = 'train.py', environment=myenv, compute_target = cluster_name)\n",
    "\n",
    "experiment = Experiment(workspace=ws, name = \"vae-no-teacher-forcing-run-410i\" )\n",
    "run = experiment.submit(config= script_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.wait_for_completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
