{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "teacher_forcing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bex2vIffA9e9",
        "outputId": "400166dd-63f2-4335-ae81-43294e78360e"
      },
      "source": [
        "!curl -Lo conda_installer.py https://raw.githubusercontent.com/deepchem/deepchem/master/scripts/colab_install.py\n",
        "import conda_installer\n",
        "conda_installer.install()\n",
        "!/root/miniconda/bin/conda info -e"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  3501  100  3501    0     0  89769      0 --:--:-- --:--:-- --:--:-- 92131\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "add /root/miniconda/lib/python3.7/site-packages to PYTHONPATH\n",
            "python version: 3.7.10\n",
            "fetching installer from https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
            "done\n",
            "installing miniconda to /root/miniconda\n",
            "done\n",
            "installing rdkit, openmm, pdbfixer\n",
            "added conda-forge to channels\n",
            "added omnia to channels\n",
            "done\n",
            "conda packages installation finished!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "# conda environments:\n",
            "#\n",
            "base                  *  /root/miniconda\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "id": "4hwtuUeFB4ic",
        "outputId": "47cf4dcd-cdeb-4feb-8920-c3602eeeea5a"
      },
      "source": [
        "!pip install --pre deepchem\n",
        "import deepchem\n",
        "deepchem.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting deepchem\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/4f/918faea08e6f3e42dd955fd7309912cd01782ee62fc6e3a6047192add238/deepchem-2.6.0.dev20210406183355-py3-none-any.whl (553kB)\n",
            "\r\u001b[K     |▋                               | 10kB 18.6MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20kB 20.8MB/s eta 0:00:01\r\u001b[K     |█▊                              | 30kB 11.9MB/s eta 0:00:01\r\u001b[K     |██▍                             | 40kB 9.5MB/s eta 0:00:01\r\u001b[K     |███                             | 51kB 8.0MB/s eta 0:00:01\r\u001b[K     |███▌                            | 61kB 8.4MB/s eta 0:00:01\r\u001b[K     |████▏                           | 71kB 8.3MB/s eta 0:00:01\r\u001b[K     |████▊                           | 81kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 92kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████                          | 102kB 7.6MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 112kB 7.6MB/s eta 0:00:01\r\u001b[K     |███████                         | 122kB 7.6MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 133kB 7.6MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 143kB 7.6MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 153kB 7.6MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 163kB 7.6MB/s eta 0:00:01\r\u001b[K     |██████████                      | 174kB 7.6MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 184kB 7.6MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 194kB 7.6MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 204kB 7.6MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 215kB 7.6MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 225kB 7.6MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 235kB 7.6MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 245kB 7.6MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 256kB 7.6MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 266kB 7.6MB/s eta 0:00:01\r\u001b[K     |████████████████                | 276kB 7.6MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 286kB 7.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 296kB 7.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 307kB 7.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 317kB 7.6MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 327kB 7.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 337kB 7.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 348kB 7.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 358kB 7.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 368kB 7.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 378kB 7.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 389kB 7.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 399kB 7.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 409kB 7.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 419kB 7.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 430kB 7.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 440kB 7.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 450kB 7.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 460kB 7.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 471kB 7.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 481kB 7.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 491kB 7.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 501kB 7.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 512kB 7.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 522kB 7.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 532kB 7.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 542kB 7.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 552kB 7.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 563kB 7.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from deepchem) (1.1.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from deepchem) (1.0.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from deepchem) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deepchem) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from deepchem) (0.22.2.post1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->deepchem) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->deepchem) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->deepchem) (1.15.0)\n",
            "Installing collected packages: deepchem\n",
            "Successfully installed deepchem-2.6.0.dev20210406183355\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.6.0.dev'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "cwwvhUeeCPtG",
        "outputId": "633a6b1d-c9b1-4dfc-9741-025e9901ea14"
      },
      "source": [
        "import rdkit\n",
        "rdkit.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2020.09.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MCra7DKaCsUv",
        "outputId": "4b1c425c-dc77-4c2e-c099-998ca42031bd"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Foa09R3eDEq1",
        "outputId": "1f1c9750-a66b-4b7b-f08f-cc5df3afecd3"
      },
      "source": [
        "# LOAD THE DATASET WITH MINIMAL PRE-PROCESSING\n",
        "!mkdir zinc_data\n",
        "\n",
        "tasks, datasets, _ = deepchem.molnet.load_zinc15(\n",
        "    featurizer='raw',\n",
        "    splitter=None,\n",
        "    transformers=[],\n",
        "    data_dir='zinc_data', \n",
        "    save_dir='zinc_data')\n",
        "print(tasks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['mwt', 'logp', 'reactive']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nSVxfj0DUGq",
        "outputId": "40a0621e-91aa-408b-d205-7cd524123963"
      },
      "source": [
        "# EXTRACT THE SMILES STRINGS FROM THE DATASET\n",
        "data = datasets[0]\n",
        "train_smiles = []\n",
        "for X, _, _, _ in data.itersamples():\n",
        "    train_smiles.append(rdkit.Chem.MolToSmiles(X))\n",
        "print(len(train_smiles))\n",
        "for smile in train_smiles[0:5]:\n",
        "  print(smile)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "250000\n",
            "CCN(CCSC)C(=O)N[C@@](C)(CC)C(F)(F)F\n",
            "CC1(C)CN(C(=O)Nc2cc3ccccc3nn2)C[C@@]2(CCOC2)O1\n",
            "CC[C@H](NC(C)=O)C(=O)NCC1(NC(=O)Cc2nonc2C)CC1\n",
            "O=C(N[C@@H]1CC[C@H](F)C1)[C@H]1C[C@@H]1c1ccc2c(c1)OCCO2\n",
            "COCC(=O)N(C)CC(=O)NCC1(Nc2nccn3nnnc23)CC1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LV1LQuIUGaql"
      },
      "source": [
        "# DEFINE THE SMILES TOKENS AND MAX_LENGTHS\n",
        "tokens = set()\n",
        "for s in train_smiles:\n",
        "    tokens = tokens.union(set(s))\n",
        "tokens = sorted(list(tokens))\n",
        "max_length = max(len(s) for s in train_smiles)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12AS6-woPrsx"
      },
      "source": [
        "\"\"\"Sequence to sequence translation models.\"\"\"\n",
        "\n",
        "from deepchem.models import KerasModel, layers\n",
        "from heapq import heappush, heappushpop\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Layer, Dense, Dropout, GRU, Lambda, Conv1D, Flatten, BatchNormalization\n",
        "\n",
        "\n",
        "class VariationalRandomizer(Layer):\n",
        "  \"\"\"Add random noise to the embedding and include a corresponding loss.\"\"\"\n",
        "\n",
        "  def __init__(self, embedding_dimension, annealing_start_step,\n",
        "               annealing_final_step, **kwargs):\n",
        "    super(VariationalRandomizer, self).__init__(**kwargs)\n",
        "    self._embedding_dimension = embedding_dimension\n",
        "    self._annealing_final_step = annealing_final_step\n",
        "    self._annealing_start_step = annealing_start_step\n",
        "    self.dense_mean = Dense(embedding_dimension)\n",
        "    self.dense_stddev = Dense(embedding_dimension)\n",
        "    self.combine = layers.CombineMeanStd(training_only=True)\n",
        "\n",
        "  def call(self, inputs, training=True):\n",
        "    input, global_step = inputs\n",
        "    embedding_mean = self.dense_mean(input)\n",
        "    embedding_stddev = self.dense_stddev(input)\n",
        "    embedding = self.combine(\n",
        "        [embedding_mean, embedding_stddev], training=training)\n",
        "    mean_sq = embedding_mean * embedding_mean\n",
        "    stddev_sq = embedding_stddev * embedding_stddev\n",
        "    kl = mean_sq + stddev_sq - tf.math.log(stddev_sq + 1e-20) - 1\n",
        "    anneal_steps = self._annealing_final_step - self._annealing_start_step\n",
        "    if anneal_steps > 0:\n",
        "      current_step = tf.cast(global_step,\n",
        "                             tf.float32) - self._annealing_start_step\n",
        "      anneal_frac = tf.maximum(0.0, current_step) / anneal_steps\n",
        "      kl_scale = tf.minimum(1.0, anneal_frac * anneal_frac)\n",
        "    else:\n",
        "      kl_scale = 1.0\n",
        "    self.add_loss(0.5 * kl_scale * tf.reduce_mean(kl))\n",
        "    return embedding\n",
        "\n",
        "\n",
        "class SeqToSeq(KerasModel):\n",
        "  \"\"\"Implements sequence to sequence translation models.\n",
        "  The model is based on the description in Sutskever et al., \"Sequence to\n",
        "  Sequence Learning with Neural Networks\" (https://arxiv.org/abs/1409.3215),\n",
        "  although this implementation uses GRUs instead of LSTMs.  The goal is to\n",
        "  take sequences of tokens as input, and translate each one into a different\n",
        "  output sequence.  The input and output sequences can both be of variable\n",
        "  length, and an output sequence need not have the same length as the input\n",
        "  sequence it was generated from.  For example, these models were originally\n",
        "  developed for use in natural language processing.  In that context, the\n",
        "  input might be a sequence of English words, and the output might be a\n",
        "  sequence of French words.  The goal would be to train the model to translate\n",
        "  sentences from English to French.\n",
        "  The model consists of two parts called the \"encoder\" and \"decoder\".  Each one\n",
        "  consists of a stack of recurrent layers.  The job of the encoder is to\n",
        "  transform the input sequence into a single, fixed length vector called the\n",
        "  \"embedding\".  That vector contains all relevant information from the input\n",
        "  sequence.  The decoder then transforms the embedding vector into the output\n",
        "  sequence.\n",
        "  These models can be used for various purposes.  First and most obviously,\n",
        "  they can be used for sequence to sequence translation.  In any case where you\n",
        "  have sequences of tokens, and you want to translate each one into a different\n",
        "  sequence, a SeqToSeq model can be trained to perform the translation.\n",
        "  Another possible use case is transforming variable length sequences into\n",
        "  fixed length vectors.  Many types of models require their inputs to have a\n",
        "  fixed shape, which makes it difficult to use them with variable sized inputs\n",
        "  (for example, when the input is a molecule, and different molecules have\n",
        "  different numbers of atoms).  In that case, you can train a SeqToSeq model as\n",
        "  an autoencoder, so that it tries to make the output sequence identical to the\n",
        "  input one.  That forces the embedding vector to contain all information from\n",
        "  the original sequence.  You can then use the encoder for transforming\n",
        "  sequences into fixed length embedding vectors, suitable to use as inputs to\n",
        "  other types of models.\n",
        "  Another use case is to train the decoder for use as a generative model.  Here\n",
        "  again you begin by training the SeqToSeq model as an autoencoder.  Once\n",
        "  training is complete, you can supply arbitrary embedding vectors, and\n",
        "  transform each one into an output sequence.  When used in this way, you\n",
        "  typically train it as a variational autoencoder.  This adds random noise to\n",
        "  the encoder, and also adds a constraint term to the loss that forces the\n",
        "  embedding vector to have a unit Gaussian distribution.  You can then pick\n",
        "  random vectors from a Gaussian distribution, and the output sequences should\n",
        "  follow the same distribution as the training data.\n",
        "  When training as a variational autoencoder, it is best to use KL cost\n",
        "  annealing, as described in https://arxiv.org/abs/1511.06349.  The constraint\n",
        "  term in the loss is initially set to 0, so the optimizer just tries to\n",
        "  minimize the reconstruction loss.  Once it has made reasonable progress\n",
        "  toward that, the constraint term can be gradually turned back on.  The range\n",
        "  of steps over which this happens is configurable.\n",
        "  \"\"\"\n",
        "\n",
        "  sequence_end = object()\n",
        "\n",
        "  def __init__(self,\n",
        "               input_tokens,\n",
        "               output_tokens,\n",
        "               max_output_length,\n",
        "               encoder_layers=4,\n",
        "               decoder_layers=4,\n",
        "               embedding_dimension=512,\n",
        "               dropout=0.0,\n",
        "               reverse_input=True,\n",
        "               variational=False,\n",
        "               annealing_start_step=5000,\n",
        "               annealing_final_step=10000,\n",
        "               **kwargs):\n",
        "    \"\"\"Construct a SeqToSeq model.\n",
        "    In addition to the following arguments, this class also accepts all the keyword arguments\n",
        "    from TensorGraph.\n",
        "    Parameters\n",
        "    ----------\n",
        "    input_tokens: list\n",
        "      a list of all tokens that may appear in input sequences\n",
        "    output_tokens: list\n",
        "      a list of all tokens that may appear in output sequences\n",
        "    max_output_length: int\n",
        "      the maximum length of output sequence that may be generated\n",
        "    encoder_layers: int\n",
        "      the number of recurrent layers in the encoder\n",
        "    decoder_layers: int\n",
        "      the number of recurrent layers in the decoder\n",
        "    embedding_dimension: int\n",
        "      the width of the embedding vector.  This also is the width of all\n",
        "      recurrent layers.\n",
        "    dropout: float\n",
        "      the dropout probability to use during training\n",
        "    reverse_input: bool\n",
        "      if True, reverse the order of input sequences before sending them into\n",
        "      the encoder.  This can improve performance when working with long sequences.\n",
        "    variational: bool\n",
        "      if True, train the model as a variational autoencoder.  This adds random\n",
        "      noise to the encoder, and also constrains the embedding to follow a unit\n",
        "      Gaussian distribution.\n",
        "    annealing_start_step: int\n",
        "      the step (that is, batch) at which to begin turning on the constraint term\n",
        "      for KL cost annealing\n",
        "    annealing_final_step: int\n",
        "      the step (that is, batch) at which to finish turning on the constraint term\n",
        "      for KL cost annealing\n",
        "    \"\"\"\n",
        "    if SeqToSeq.sequence_end not in input_tokens:\n",
        "      input_tokens = input_tokens + [SeqToSeq.sequence_end]\n",
        "    if SeqToSeq.sequence_end not in output_tokens:\n",
        "      output_tokens = output_tokens + [SeqToSeq.sequence_end]\n",
        "    self._input_tokens = input_tokens\n",
        "    self._output_tokens = output_tokens\n",
        "    self._input_dict = dict((x, i) for i, x in enumerate(input_tokens))\n",
        "    self._output_dict = dict((x, i) for i, x in enumerate(output_tokens))\n",
        "    self._max_output_length = max_output_length\n",
        "    self._embedding_dimension = embedding_dimension\n",
        "    self._reverse_input = reverse_input\n",
        "    self.encoder = self._create_encoder(encoder_layers, dropout)\n",
        "    self.decoder = self._create_decoder(decoder_layers, dropout)\n",
        "    features = self._create_features()\n",
        "    gather_indices = Input(shape=(2,), dtype=tf.int32)\n",
        "    global_step = Input(shape=tuple(), dtype=tf.int32)\n",
        "    embedding = self.encoder([features, gather_indices])\n",
        "    self._embedding = self.encoder([features, gather_indices], training=False)\n",
        "    if variational:\n",
        "      randomizer = VariationalRandomizer(\n",
        "          self._embedding_dimension, annealing_start_step, annealing_final_step)\n",
        "      embedding = randomizer([self._embedding, global_step])\n",
        "      self._embedding = randomizer(\n",
        "          [self._embedding, global_step], training=False)\n",
        "    output = self.decoder(embedding)\n",
        "    model = tf.keras.Model(\n",
        "              inputs=[features, gather_indices, global_step], \n",
        "              outputs=output\n",
        "              )\n",
        "    super(SeqToSeq, self).__init__(model, self._create_loss(), **kwargs)\n",
        "\n",
        "  def _create_features(self):\n",
        "    return Input(shape=(None, len(self._input_tokens)))\n",
        "\n",
        "  def _create_encoder(self, n_layers, dropout):\n",
        "    \"\"\"Create the encoder as a tf.keras.Model.\"\"\"\n",
        "    input = self._create_features()\n",
        "    gather_indices = Input(shape=(2,), dtype=tf.int32)\n",
        "    prev_layer = input\n",
        "    for i in range(n_layers):\n",
        "      if dropout > 0.0:\n",
        "        prev_layer = Dropout(rate=dropout)(prev_layer)\n",
        "      prev_layer = GRU(\n",
        "          self._embedding_dimension, return_sequences=True)(prev_layer)\n",
        "    prev_layer = Lambda(lambda x: tf.gather_nd(x[0], x[1]))(\n",
        "        [prev_layer, gather_indices])\n",
        "    return tf.keras.Model(inputs=[input, gather_indices], outputs=prev_layer)\n",
        "\n",
        "  def _create_decoder(self, n_layers, dropout):\n",
        "    \"\"\"Create the decoder as a tf.keras.Model.\"\"\"\n",
        "    input = Input(shape=(self._embedding_dimension,))\n",
        "    prev_layer = layers.Stack()(self._max_output_length * [input])\n",
        "    for i in range(n_layers):\n",
        "      if dropout > 0.0:\n",
        "        prev_layer = Dropout(dropout)(prev_layer)\n",
        "      prev_layer = GRU(\n",
        "          self._embedding_dimension, return_sequences=True)(prev_layer)\n",
        "    output = Dense(\n",
        "        len(self._output_tokens), activation=tf.nn.softmax)(prev_layer)\n",
        "    return tf.keras.Model(inputs=input, outputs=output)\n",
        "\n",
        "  def _create_loss(self):\n",
        "    \"\"\"Create the loss function.\"\"\"\n",
        "\n",
        "    def loss_fn(outputs, labels, weights):\n",
        "      prob = tf.reduce_sum(outputs[0] * labels[0], axis=2)\n",
        "      mask = tf.reduce_sum(labels[0], axis=2)\n",
        "      log_prob = tf.math.log(prob + 1e-20) * mask\n",
        "      loss = -tf.reduce_mean(tf.reduce_sum(log_prob, axis=1))\n",
        "      return loss + sum(self.model.losses)\n",
        "\n",
        "    return loss_fn\n",
        "\n",
        "  def fit_sequences(self,\n",
        "                    sequences,\n",
        "                    max_checkpoints_to_keep=5,\n",
        "                    checkpoint_interval=1000,\n",
        "                    restore=False):\n",
        "    \"\"\"Train this model on a set of sequences\n",
        "    Parameters\n",
        "    ----------\n",
        "    sequences: iterable\n",
        "      the training samples to fit to.  Each sample should be\n",
        "      represented as a tuple of the form (input_sequence, output_sequence).\n",
        "    max_checkpoints_to_keep: int\n",
        "      the maximum number of checkpoints to keep.  Older checkpoints are discarded.\n",
        "    checkpoint_interval: int\n",
        "      the frequency at which to write checkpoints, measured in training steps.\n",
        "    restore: bool\n",
        "      if True, restore the model from the most recent checkpoint and continue training\n",
        "      from there.  If False, retrain the model from scratch.\n",
        "    \"\"\"\n",
        "    self.fit_generator(\n",
        "        self._generate_batches(sequences),\n",
        "        max_checkpoints_to_keep=max_checkpoints_to_keep,\n",
        "        checkpoint_interval=checkpoint_interval,\n",
        "        restore=restore)\n",
        "\n",
        "  def predict_from_sequences(self, sequences, beam_width=5):\n",
        "    \"\"\"Given a set of input sequences, predict the output sequences.\n",
        "    The prediction is done using a beam search with length normalization.\n",
        "    Parameters\n",
        "    ----------\n",
        "    sequences: iterable\n",
        "      the input sequences to generate a prediction for\n",
        "    beam_width: int\n",
        "      the beam width to use for searching.  Set to 1 to use a simple greedy search.\n",
        "    \"\"\"\n",
        "    result = []\n",
        "    for batch in self._batch_elements(sequences):\n",
        "      features = self._create_input_array(batch)\n",
        "      indices = np.array([(i, len(batch[i]) if i < len(batch) else 0)\n",
        "                          for i in range(self.batch_size)])\n",
        "      probs = self.predict_on_generator([[(features, indices,\n",
        "                                           np.array(self.get_global_step())),\n",
        "                                          None, None]])\n",
        "      for i in range(len(batch)):\n",
        "        result.append(self._beam_search(probs[i], beam_width))\n",
        "    return result\n",
        "\n",
        "  def predict_from_embeddings(self, embeddings, beam_width=5):\n",
        "    \"\"\"Given a set of embedding vectors, predict the output sequences.\n",
        "    The prediction is done using a beam search with length normalization.\n",
        "    Parameters\n",
        "    ----------\n",
        "    embeddings: iterable\n",
        "      the embedding vectors to generate predictions for\n",
        "    beam_width: int\n",
        "      the beam width to use for searching.  Set to 1 to use a simple greedy search.\n",
        "    \"\"\"\n",
        "    result = []\n",
        "    for batch in self._batch_elements(embeddings):\n",
        "      embedding_array = np.zeros(\n",
        "          (self.batch_size, self._embedding_dimension), dtype=np.float32)\n",
        "      for i, e in enumerate(batch):\n",
        "        embedding_array[i] = e\n",
        "      probs = self.decoder(embedding_array, training=False)\n",
        "      probs = probs.numpy()\n",
        "      for i in range(len(batch)):\n",
        "        result.append(self._beam_search(probs[i], beam_width))\n",
        "    return result\n",
        "\n",
        "  def predict_embeddings(self, sequences):\n",
        "    \"\"\"Given a set of input sequences, compute the embedding vectors.\n",
        "    Parameters\n",
        "    ----------\n",
        "    sequences: iterable\n",
        "      the input sequences to generate an embedding vector for\n",
        "    \"\"\"\n",
        "    result = []\n",
        "    for batch in self._batch_elements(sequences):\n",
        "      features = self._create_input_array(batch)\n",
        "      indices = np.array([(i, len(batch[i]) if i < len(batch) else 0)\n",
        "                          for i in range(self.batch_size)])\n",
        "      embeddings = self.predict_on_generator(\n",
        "          [[(features, indices, np.array(self.get_global_step())), None, None]],\n",
        "          outputs=self._embedding)\n",
        "      for i in range(len(batch)):\n",
        "        result.append(embeddings[i])\n",
        "    return np.array(result, dtype=np.float32)\n",
        "\n",
        "  def _beam_search(self, probs, beam_width):\n",
        "    \"\"\"Perform a beam search for the most likely output sequence.\"\"\"\n",
        "    if beam_width == 1:\n",
        "      # Do a simple greedy search.\n",
        "\n",
        "      s = []\n",
        "      for i in range(len(probs)):\n",
        "        token = self._output_tokens[np.argmax(probs[i])]\n",
        "        if token == SeqToSeq.sequence_end:\n",
        "          break\n",
        "        s.append(token)\n",
        "      return s\n",
        "\n",
        "    # Do a beam search with length normalization.\n",
        "\n",
        "    logprobs = np.log(probs)\n",
        "    # Represent each candidate as (normalized prob, raw prob, sequence)\n",
        "    candidates = [(0.0, 0.0, [])]\n",
        "    for i in range(len(logprobs)):\n",
        "      new_candidates = []\n",
        "      for c in candidates:\n",
        "        if len(c[2]) > 0 and c[2][-1] == SeqToSeq.sequence_end:\n",
        "          # This candidate sequence has already been terminated\n",
        "          if len(new_candidates) < beam_width:\n",
        "            heappush(new_candidates, c)\n",
        "          else:\n",
        "            heappushpop(new_candidates, c)\n",
        "        else:\n",
        "          # Consider all possible tokens we could add to this candidate sequence.\n",
        "          for j, logprob in enumerate(logprobs[i]):\n",
        "            new_logprob = logprob + c[1]\n",
        "            newc = (new_logprob / (len(c[2]) + 1), new_logprob,\n",
        "                    c[2] + [self._output_tokens[j]])\n",
        "            if len(new_candidates) < beam_width:\n",
        "              heappush(new_candidates, newc)\n",
        "            else:\n",
        "              heappushpop(new_candidates, newc)\n",
        "      candidates = new_candidates\n",
        "    return sorted(candidates)[-1][2][:-1]\n",
        "\n",
        "  def _create_input_array(self, sequences):\n",
        "    \"\"\"Create the array describing the input sequences for a batch.\"\"\"\n",
        "    lengths = [len(x) for x in sequences]\n",
        "    if self._reverse_input:\n",
        "      sequences = [reversed(s) for s in sequences]\n",
        "    features = np.zeros(\n",
        "        (self.batch_size, max(lengths) + 1, len(self._input_tokens)),\n",
        "        dtype=np.float32)\n",
        "    for i, sequence in enumerate(sequences):\n",
        "      for j, token in enumerate(sequence):\n",
        "        features[i, j, self._input_dict[token]] = 1\n",
        "    features[np.arange(len(sequences)), lengths, self._input_dict[\n",
        "        SeqToSeq.sequence_end]] = 1\n",
        "    return features\n",
        "\n",
        "  def _create_output_array(self, sequences):\n",
        "    \"\"\"Create the array describing the target sequences for a batch.\"\"\"\n",
        "    lengths = [len(x) for x in sequences]\n",
        "    labels = np.zeros(\n",
        "        (self.batch_size, self._max_output_length, len(self._output_tokens)),\n",
        "        dtype=np.float32)\n",
        "    end_marker_index = self._output_dict[SeqToSeq.sequence_end]\n",
        "    for i, sequence in enumerate(sequences):\n",
        "      for j, token in enumerate(sequence):\n",
        "        labels[i, j, self._output_dict[token]] = 1\n",
        "      for j in range(lengths[i], self._max_output_length):\n",
        "        labels[i, j, end_marker_index] = 1\n",
        "    return labels\n",
        "\n",
        "  def _batch_elements(self, elements):\n",
        "    \"\"\"Combine elements into batches.\"\"\"\n",
        "    batch = []\n",
        "    for s in elements:\n",
        "      batch.append(s)\n",
        "      if len(batch) == self.batch_size:\n",
        "        yield batch\n",
        "        batch = []\n",
        "    if len(batch) > 0:\n",
        "      yield batch\n",
        "\n",
        "  def _generate_batches(self, sequences):\n",
        "    \"\"\"Create feed_dicts for fitting.\"\"\"\n",
        "    for batch in self._batch_elements(sequences):\n",
        "      inputs = []\n",
        "      outputs = []\n",
        "      for input, output in batch:\n",
        "        inputs.append(input)\n",
        "        outputs.append(output)\n",
        "      for i in range(len(inputs), self.batch_size):\n",
        "        inputs.append([])\n",
        "        outputs.append([])\n",
        "      features = self._create_input_array(inputs)\n",
        "      labels = self._create_output_array(outputs)\n",
        "      gather_indices = np.array([(i, len(x)) for i, x in enumerate(inputs)])\n",
        "      yield ([features, gather_indices,\n",
        "              np.array(self.get_global_step())], [labels], [])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBfQrtOknCbm"
      },
      "source": [
        "\n",
        "class AspuruGuzikAutoEncoder(SeqToSeq):\n",
        "  \"\"\"\n",
        "  This is an implementation of Automatic Chemical Design Using a Continuous Representation of Molecules\n",
        "  http://pubs.acs.org/doi/full/10.1021/acscentsci.7b00572\n",
        "  Abstract\n",
        "  --------\n",
        "  We report a method to convert discrete representations of molecules to and\n",
        "  from a multidimensional continuous representation. This model allows us to\n",
        "  generate new molecules for efficient exploration and optimization through\n",
        "  open-ended spaces of chemical compounds. A deep neural network was trained on\n",
        "  hundreds of thousands of existing chemical structures to construct three\n",
        "  coupled functions: an encoder, a decoder, and a predictor. The encoder\n",
        "  converts the discrete representation of a molecule into a real-valued\n",
        "  continuous vector, and the decoder converts these continuous vectors back to\n",
        "  discrete molecular representations. The predictor estimates chemical\n",
        "  properties from the latent continuous vector representation of the molecule.\n",
        "  Continuous representations of molecules allow us to automatically generate\n",
        "  novel chemical structures by performing simple operations in the latent space,\n",
        "  such as decoding random vectors, perturbing known chemical structures, or\n",
        "  interpolating between molecules. Continuous representations also allow the use\n",
        "  of powerful gradient-based optimization to efficiently guide the search for\n",
        "  optimized functional compounds. We demonstrate our method in the domain of\n",
        "  drug-like molecules and also in a set of molecules with fewer that nine heavy\n",
        "  atoms.\n",
        "  Notes\n",
        "  -------\n",
        "  This is currently an imperfect reproduction of the paper.  One difference is\n",
        "  that teacher forcing in the decoder is not implemented.  The paper also\n",
        "  discusses co-learning molecular properties at the same time as training the\n",
        "  encoder/decoder.  This is not done here.  The hyperparameters chosen are from\n",
        "  ZINC dataset.\n",
        "  This network also currently suffers from exploding gradients.  Care has to be taken when training.\n",
        "  NOTE(LESWING): Will need to play around with annealing schedule to not have exploding gradients\n",
        "  TODO(LESWING): Teacher Forcing\n",
        "  TODO(LESWING): Sigmoid variational loss annealing schedule\n",
        "  The output GRU layer had one\n",
        "  additional input, corresponding to the character sampled from the softmax output of the\n",
        "  previous time step and was trained using teacher forcing. 48 This increased the accuracy\n",
        "  of generated SMILES strings, which resulted in higher fractions of valid SMILES strings\n",
        "  for latent points outside the training data, but also made training more difficult, since the\n",
        "  decoder showed a tendency to ignore the (variational) encoding and rely solely on the input\n",
        "  sequence. The variational loss was annealed according to sigmoid schedule after 29 epochs,\n",
        "  running for a total 120 epochs\n",
        "  I also added a BatchNorm before the mean and std embedding layers.  This has empirically\n",
        "  made training more stable, and is discussed in Ladder Variational Autoencoders.\n",
        "  https://arxiv.org/pdf/1602.02282.pdf\n",
        "  Maybe if Teacher Forcing and Sigmoid variational loss annealing schedule are used the\n",
        "  BatchNorm will no longer be neccessary.\n",
        "\n",
        "  Enhancement Notes April 2021 (A. Jacobson, D. Liang, J. Judge, M. Masanz):\n",
        "  Implementing teacher forcing \n",
        "  We rely on tgru_k2_gpu.py \"TerminalGRU\" of Aspuru-Guzik-group's \n",
        "      original repository as a reference.\n",
        "  With probability equal to the teaching forcing ratio (teacher_forcing_ratio)\n",
        "     we use the actual ground-truth input in the sequence as the input to\n",
        "     the decoder during the next time-step. \n",
        "  However, with probability  (1 - teacher_forcing_ratio) \n",
        "      we use the output that the model predicted as the next input to the model.\n",
        "  As noted above, this is expected to alleviate some problems with training \n",
        "    stability. It is also expected to improve the percentage of generated\n",
        "    molecules that are valid, by allowing the decoder to begin learning even \n",
        "    before the encoder has learned to create an informative latent space. \n",
        "    However, the drawback is that teacher forcing can limit the influence of \n",
        "    the latent space and thus its expression of novel predictions when \n",
        "    generating molecules.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               num_tokens,\n",
        "               max_output_length,\n",
        "               embedding_dimension=196,\n",
        "               filter_sizes=[9, 9, 10],\n",
        "               kernel_sizes=[9, 9, 11],\n",
        "               decoder_dimension=488,\n",
        "               teacher_forcing_ratio=0.5,\n",
        "               **kwargs):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    filter_sizes: list of int\n",
        "      Number of filters for each 1D convolution in the encoder\n",
        "    kernel_sizes: list of int\n",
        "      Kernel size for each 1D convolution in the encoder\n",
        "    decoder_dimension: int\n",
        "      Number of channels for the GRU Decoder\n",
        "    teacher_forcing_ratio: float in range [0,1]\n",
        "      probability of replacing the input to the teacher-forced decoder\n",
        "      layer with the grouth-truth input\n",
        "    \"\"\"\n",
        "    if len(filter_sizes) != len(kernel_sizes):\n",
        "      raise ValueError(\"Must have same number of layers and kernels\")\n",
        "    self._filter_sizes = filter_sizes\n",
        "    self._kernel_sizes = kernel_sizes\n",
        "    self._decoder_dimension = decoder_dimension\n",
        "    sel._teacher_forcing_ratio = teacher_forcing_ratio\n",
        "    super(AspuruGuzikAutoEncoder, self).__init__(\n",
        "        input_tokens=num_tokens,\n",
        "        output_tokens=num_tokens,\n",
        "        max_output_length=max_output_length,\n",
        "        embedding_dimension=embedding_dimension,\n",
        "        variational=True,\n",
        "        reverse_input=False,\n",
        "        **kwargs)\n",
        "\n",
        "  def _create_features(self):\n",
        "    return Input(shape=(self._max_output_length, len(self._input_tokens)))\n",
        "\n",
        "  def _create_encoder(self, n_layers, dropout):\n",
        "    \"\"\"Create the encoder as a tf.keras.Model.\"\"\"\n",
        "    input = self._create_features()\n",
        "    gather_indices = Input(shape=(2,), dtype=tf.int32)\n",
        "    prev_layer = input\n",
        "    for i in range(len(self._filter_sizes)):\n",
        "      filter_size = self._filter_sizes[i]\n",
        "      kernel_size = self._kernel_sizes[i]\n",
        "      if dropout > 0.0:\n",
        "        prev_layer = Dropout(rate=dropout)(prev_layer)\n",
        "      prev_layer = Conv1D(\n",
        "          filters=filter_size, kernel_size=kernel_size,\n",
        "          activation=tf.nn.relu)(prev_layer)\n",
        "    prev_layer = Flatten()(prev_layer)\n",
        "    prev_layer = Dense(\n",
        "        self._decoder_dimension, activation=tf.nn.relu)(prev_layer)\n",
        "    prev_layer = BatchNormalization()(prev_layer)\n",
        "    return tf.keras.Model(inputs=[input, gather_indices], outputs=prev_layer)\n",
        "\n",
        "  def _create_decoder(self, n_layers, dropout):\n",
        "    \"\"\"Create the decoder as a tf.keras.Model.\"\"\"\n",
        "    input = Input(shape=(self._embedding_dimension,))\n",
        "    prev_layer = Dense(self._embedding_dimension, activation=tf.nn.relu)(input)\n",
        "    prev_layer = layers.Stack()(self._max_output_length * [prev_layer])\n",
        "    for i in range(3):\n",
        "      if dropout > 0.0:\n",
        "        prev_layer = Dropout(dropout)(prev_layer)\n",
        "      prev_layer = GRU(\n",
        "          self._decoder_dimension, return_sequences=True)(prev_layer)\n",
        "    output = Dense(\n",
        "        len(self._output_tokens), activation=tf.nn.softmax)(prev_layer)\n",
        "    return tf.keras.Model(inputs=input, outputs=output)\n",
        "\n",
        "  def _create_input_array(self, sequences):\n",
        "    return self._create_output_array(sequences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZytUDZv0W6FO"
      },
      "source": [
        "# DEFINE THE MODEL\n",
        "from deepchem.models.optimizers import Adam, ExponentialDecay\n",
        "\n",
        "\n",
        "def get_model():\n",
        "    batch_size = 100\n",
        "    learning_rate = ExponentialDecay(0.001, 0.95, len(train_smiles)/batch_size)\n",
        "    model = AspuruGuzikAutoEncoder(tokens, max_length, model_dir='vae', batch_size=batch_size, learning_rate=learning_rate)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8edPVnBXDzW"
      },
      "source": [
        "# TRAINING\n",
        "def generate_sequences(epochs): \n",
        "    for i in range(epochs):\n",
        "        print('epoch:', i+1)\n",
        "        for s in train_smiles: \n",
        "            yield (s, s)\n",
        "\n",
        "#deepchem has its own fit model variation\n",
        "def train(model, epochs=1):\n",
        "    model.fit_sequences(generate_sequences(epochs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WhmDnqXfBXY"
      },
      "source": [
        "# GENERATE MOLECULES AND TEST IF THEY ARE VALID\n",
        "import numpy as np\n",
        "\n",
        "def generate_molecules(model, n_molecules=1000):\n",
        "    predictions = model.predict_from_embeddings(np.random.normal(size=(n_molecules,196))) \n",
        "    valid = []\n",
        "\n",
        "    #using chem from rdkit to ensure generated molecules are valid\n",
        "    count = 0\n",
        "    for p in predictions:\n",
        "      count += 1\n",
        "      smiles = ''.join(p)\n",
        "      if count < 25:\n",
        "        print(smiles)\n",
        "      if rdkit.Chem.MolFromSmiles(smiles) is not None:\n",
        "        valid.append(smiles) \n",
        "\n",
        "    print(len(valid) / n_molecules)\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "p8PdQgBjfsvC",
        "outputId": "71f625e0-cf75-4acc-f958-e02de98bb5e9"
      },
      "source": [
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAtzQveGgw9a",
        "outputId": "6466edc3-bb55-4603-83db-77e3b881e926"
      },
      "source": [
        "with tf.device('/device:GPU:0'):\n",
        "    model = get_model()\n",
        "    train(model, 10)\n",
        "    generate_molecules(model)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 1\n",
            "epoch: 2\n",
            "epoch: 3\n",
            "epoch: 4\n",
            "epoch: 5\n",
            "epoch: 6\n",
            "epoch: 7\n",
            "epoch: 8\n",
            "epoch: 9\n",
            "epoch: 10\n",
            "CC(C)()S(=)(=O)/)(C)CCC)(C)C)(C)/CC)CC)C)))))n1\n",
            "CC(C)(C)CCC(=)CC(C)C1CCCC(((CC(CCCCCCCC2CCc2cc(CCC)c)cccc]1\n",
            "CC(C)CC(CC)(=O)CC(=O)C(=O)C(=)C1CCCCCCC2C11\n",
            "CCSS(=O)(=O)/C)/)/)CC(C)C(=O)/C=C)C(C)C)n1\n",
            "O=C(C)CCCCCCC)C(=O)OCCCCCCC(C))C)C)C(=O)=O))C1\n",
            "CCCCC(C)(C)C)C)C(=O)C(C)(F)F)CCC(F))))c1C\n",
            "CC(C(O)CCCCC)CC((C)())C)CCC)(C)()(()(((CCCCCCC)cc\n",
            "CCC())C(C)CCCCC1CN(C(=O)OCC)(=O)=O)c()c2C)C1\n",
            "CC(C)(CCCC@@H]1CC@@]1[C@@H]1CC@H]1CC@HH]CCC@@H]1CC@@H]CCC@@H]CCCC@H]1CCCC@H]1CCC@@H]CCCC@H]1C\n",
            "CC(()CC((CCCC)(C)F)=C)C)C)CC1111CCC22222222222222222CCC))c1cc11\n",
            "Cc1cc(C(=O)O=C)CC(C)CCC)CCC(CCCCCCCCC2)1\n",
            "CN(C)C)=C)C))(=)(=O)=O)N(CCNC(=O)C(C)CCC)=\n",
            "CN(C)C(=O)CC(=O)/(=O)CCCC)CCCCCCCCC)CCC1\n",
            "CCN(CCCC)(C)C)C)C)CCCC)CC(()(C)(F)=F)c1\n",
            "CC(C)(=O)C1)cc(C(C)CCCC@@]22CCCC2)cnn1\n",
            "CCCCC(C)=C)C1CC(F)(F)F)=C)C1CC((F)(F)(F)F)C11\n",
            "CC(C)(C)CCCC(C)CC)C)(C)C(CS(=O)(=O)OC)C1\n",
            "CC(()CC(C)(C)C)=))C(=O)NCCCC)C1CC((C))=F)F)\n",
            "C[C@H](NC(=))C)C(=O)C(N)=C)C(C)CCCC))CC(C)(O)\n",
            "Cc1c(C(=O)NCCC(CC)C2CCCC(CCCC)CC)2(=O)2cccc1C\n",
            "CC((C()CC))(=O)C(=O)N=C)CCCCCCCCCC)1CCc)ccn1\n",
            "CCCC(=(=O((=O)N(C)CCCCCCCCCC)CCCCCCCCCC)C))1\n",
            "CC(=O)N((C)(())))CC(C)(=O)(=O)OCC))))n1\n",
            "CC(C)(C)(=O)/CCCCC)(C)C(C)(C)C)C)FCCCC1\n",
            "0.004\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}